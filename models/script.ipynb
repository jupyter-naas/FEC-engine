{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "touched-standard",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"10%\" alt=\"Naas\" src=\"https://landen.imgix.net/jtci2pxwjczr/assets/5ice39g4.png?w=160\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-needle",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# FEC - Creer un dashboard PowerBI\n",
    "<a href=\"https://app.naas.ai/user-redirect/naas/downloader?url=https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/FEC/FEC_Creer_un_dashboard_PowerBI.ipynb\" target=\"_parent\"><img src=\"https://naasai-public.s3.eu-west-3.amazonaws.com/open_in_naas.svg\"/></a><br><br><a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=&template=template-request.md&title=Tool+-+Action+of+the+notebook+\">Template request</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=FEC+-+Creer+un+dashboard+PowerBI:+Error+short+description\">Bug report</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-library",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-17T08:30:57.908317Z",
     "iopub.status.busy": "2021-08-17T08:30:57.908010Z",
     "iopub.status.idle": "2021-08-17T08:30:57.920293Z",
     "shell.execute_reply": "2021-08-17T08:30:57.919475Z",
     "shell.execute_reply.started": "2021-08-17T08:30:57.908246Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #fec #powerbi #dataviz #analytics #finance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-nightmare",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Alexandre STEVENS](https://www.linkedin.com/in/alexandrestevenspbix/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naas-description",
   "metadata": {
    "papermill": {},
    "tags": [
     "description"
    ]
   },
   "source": [
    "**Description:** This notebook provides instructions for creating a PowerBI dashboard to visualize Federal Election Commission (FEC) data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-laptop",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-beatles",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Librairie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amazing-pollution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T10:06:18.476308Z",
     "iopub.status.busy": "2023-03-30T10:06:18.476023Z",
     "iopub.status.idle": "2023-03-30T10:06:20.102017Z",
     "shell.execute_reply": "2023-03-30T10:06:20.099948Z",
     "shell.execute_reply.started": "2023-03-30T10:06:18.476223Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'contextfilter' from 'jinja2' (/home/ftp/.local/lib/python3.9/site-packages/jinja2/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-885df5d20bd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnaas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/naas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJavascript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotifications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotifications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_var\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mn_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/naas/runner/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunner\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnaas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_var\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mn_env\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/naas/runner/runner.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mescape_kubernet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnotebooks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotebooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0menv_var\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mn_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/naas/runner/notebooks.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmime_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnbconvert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTMLExporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0menv_var\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msanic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nbconvert/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexporters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nbconvert/exporters/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m from .base import (export, get_exporter,\n\u001b[1;32m      2\u001b[0m                    ExporterNameError, get_export_names)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTMLExporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mslides\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSlidesExporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtemplateexporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemplateExporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nbconvert/exporters/html.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtraitlets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjupyter_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaths\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjupyter_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjinja2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontextfilter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjinja2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplit_template_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjinja2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'contextfilter' from 'jinja2' (/home/ftp/.local/lib/python3.9/site-packages/jinja2/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import re\n",
    "import naas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-touch",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Lien URL vers le logo de l'entreprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-peoples",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.102684Z",
     "iopub.status.idle": "2023-03-30T10:06:20.102908Z",
     "shell.execute_reply": "2023-03-30T10:06:20.102805Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOGO = \"https://landen.imgix.net/e5hx7wyzf53f/assets/26u7xg7u.png?w=400\"\n",
    "COLOR_1 = None\n",
    "COLOR_2 = None\n",
    "INPUT_FOLDER = '../inputs/'\n",
    "OUTPUT_FOLDER = '../outputs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-driver",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Lire les fichiers FEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-karaoke",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.103647Z",
     "iopub.status.idle": "2023-03-30T10:06:20.103957Z",
     "shell.execute_reply": "2023-03-30T10:06:20.103798Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_fec(\n",
    "    input_folder,\n",
    "    file_regex,\n",
    "    sep=\",\",\n",
    "    decimal=\".\",\n",
    "    encoding=None,\n",
    "    header=None,\n",
    "    usecols=None,\n",
    "    names=None,\n",
    "    dtype=None,\n",
    "):\n",
    "    # Create df init\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Get all files in INPUT_FOLDER\n",
    "    files = [f for f in os.listdir(input_folder) if re.search(file_regex, f)]\n",
    "    if len(files) == 0:\n",
    "        print(f\"Aucun fichier FEC ne correspond au standard de nomination\")\n",
    "    else:\n",
    "        for file in files:\n",
    "            # Open file and create df\n",
    "            print(file)\n",
    "            tmp_df = pd.read_csv(\n",
    "                f'{input_folder}{file}',\n",
    "                sep=sep,\n",
    "                decimal=decimal,\n",
    "                encoding=encoding,\n",
    "                header=header,\n",
    "                usecols=usecols,\n",
    "                names=names,\n",
    "                dtype=dtype,\n",
    "            )\n",
    "            # Add filename to df\n",
    "            tmp_df[\"NOM_FICHIER\"] = file\n",
    "\n",
    "            # Concat df\n",
    "            df = pd.concat([df, tmp_df], axis=0, sort=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-brain",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.116961Z",
     "iopub.status.idle": "2023-03-30T10:06:20.117301Z",
     "shell.execute_reply": "2023-03-30T10:06:20.117136Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_regex = \"^\\d{9}FEC\\d{8}.txt\"\n",
    "\n",
    "db_init = get_all_fec(\n",
    "    INPUT_FOLDER, file_regex, sep=\"\\t\", decimal=\",\", encoding=\"ISO-8859-1\", header=0\n",
    ")\n",
    "db_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-wallpaper",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-country",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Base de donnée FEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-messenger",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-accident",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.118261Z",
     "iopub.status.idle": "2023-03-30T10:06:20.118723Z",
     "shell.execute_reply": "2023-03-30T10:06:20.118550Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_clean = db_init.copy()\n",
    "\n",
    "# Selection des colonnes à conserver\n",
    "to_select = [\n",
    "    \"NOM_FICHIER\",\n",
    "    \"EcritureDate\",\n",
    "    \"CompteNum\",\n",
    "    \"CompteLib\",\n",
    "    \"EcritureLib\",\n",
    "    \"Debit\",\n",
    "    \"Credit\",\n",
    "]\n",
    "db_clean = db_clean[to_select]\n",
    "\n",
    "# Renommage des colonnes\n",
    "to_rename = {\n",
    "    \"EcritureDate\": \"DATE\",\n",
    "    \"CompteNum\": \"COMPTE_NUM\",\n",
    "    \"CompteLib\": \"RUBRIQUE_N3\",\n",
    "    \"EcritureLib\": \"RUBRIQUE_N4\",\n",
    "    \"Debit\": \"DEBIT\",\n",
    "    \"Credit\": \"CREDIT\",\n",
    "}\n",
    "db_clean = db_clean.rename(columns=to_rename)\n",
    "\n",
    "# suppression des espaces colonne \"COMPTE_NUM\"\n",
    "db_clean[\"COMPTE_NUM\"] = db_clean[\"COMPTE_NUM\"].astype(str).str.strip()\n",
    "\n",
    "# Mise au format des colonnes\n",
    "db_clean = db_clean.astype(\n",
    "    {\n",
    "        \"NOM_FICHIER\": str,\n",
    "        \"DATE\": str,\n",
    "        \"COMPTE_NUM\": str,\n",
    "        \"RUBRIQUE_N3\": str,\n",
    "        \"RUBRIQUE_N4\": str,\n",
    "        \"DEBIT\": float,\n",
    "        \"CREDIT\": float,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Mise au format colonne date\n",
    "db_clean[\"DATE\"] = pd.to_datetime(db_clean[\"DATE\"])\n",
    "\n",
    "db_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-chambers",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Enrichissement de la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-industry",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.119586Z",
     "iopub.status.idle": "2023-03-30T10:06:20.119951Z",
     "shell.execute_reply": "2023-03-30T10:06:20.119785Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_enr = db_clean.copy()\n",
    "\n",
    "# Ajout colonnes entité et période\n",
    "db_enr[\"ENTITY\"] = db_enr[\"NOM_FICHIER\"].str[:9]\n",
    "db_enr[\"PERIOD\"] = db_enr[\"NOM_FICHIER\"].str[12:-6]\n",
    "db_enr[\"PERIOD\"] = pd.to_datetime(db_enr[\"PERIOD\"], format=\"%Y%m\")\n",
    "db_enr[\"PERIOD\"] = db_enr[\"PERIOD\"].dt.strftime(\"%Y-%m\")\n",
    "\n",
    "# Ajout colonne month et month_index\n",
    "db_enr[\"MONTH\"] = db_enr[\"DATE\"].dt.strftime(\"%b\")\n",
    "db_enr[\"MONTH_INDEX\"] = db_enr[\"DATE\"].dt.month\n",
    "\n",
    "# Calcul de la valeur debit-crédit\n",
    "db_enr[\"VALUE\"] = (db_enr[\"DEBIT\"]) - (db_enr[\"CREDIT\"])\n",
    "\n",
    "db_enr.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-supplement",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.120879Z",
     "iopub.status.idle": "2023-03-30T10:06:20.121254Z",
     "shell.execute_reply": "2023-03-30T10:06:20.121085Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcul résultat pour équilibrage bilan dans capitaux propre\n",
    "db_rn = db_enr.copy()\n",
    "\n",
    "db_rn = db_rn[db_rn[\"COMPTE_NUM\"].str.contains(r\"^6|^7\")]\n",
    "\n",
    "to_group = [\"ENTITY\", \"PERIOD\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "db_rn = db_rn.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "db_rn[\"COMPTE_NUM\"] = \"10999999\"\n",
    "db_rn[\"RUBRIQUE_N3\"] = \"RESULTAT\"\n",
    "\n",
    "# Reorganisation colonne\n",
    "to_select = [\"ENTITY\", \"PERIOD\", \"COMPTE_NUM\", \"RUBRIQUE_N3\", \"VALUE\"]\n",
    "db_rn = db_rn[to_select]\n",
    "db_rn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-employee",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Base de données FEC aggrégée avec variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-democrat",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Aggrégation RUBRIQUE N3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-valve",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.122108Z",
     "iopub.status.idle": "2023-03-30T10:06:20.122471Z",
     "shell.execute_reply": "2023-03-30T10:06:20.122304Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcul var v = création de dataset avec Period_comp pour merge\n",
    "db_var = db_enr.copy()\n",
    "\n",
    "# Regroupement\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"COMPTE_NUM\", \"RUBRIQUE_N3\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "db_var = db_var.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Ajout des résultats au dataframe\n",
    "db_var = pd.concat([db_var, db_rn], axis=0, sort=False)\n",
    "\n",
    "# Creation colonne COMP\n",
    "db_var[\"PERIOD_COMP\"] = (db_var[\"PERIOD\"].str[:4].astype(int) - 1).astype(str) + db_var[\n",
    "    \"PERIOD\"\n",
    "].str[-3:]\n",
    "\n",
    "db_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-qualification",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Création de la base comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-modeling",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.123336Z",
     "iopub.status.idle": "2023-03-30T10:06:20.123710Z",
     "shell.execute_reply": "2023-03-30T10:06:20.123537Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_comp = db_var.copy()\n",
    "\n",
    "# Suppression de la colonne période\n",
    "db_comp = db_comp.drop(\"PERIOD_COMP\", axis=1)\n",
    "\n",
    "# Renommage des colonnes\n",
    "to_rename = {\"VALUE\": \"VALUE_N-1\", \"PERIOD\": \"PERIOD_COMP\"}\n",
    "db_comp = db_comp.rename(columns=to_rename)\n",
    "\n",
    "db_comp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-warren",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### Jointure des 2 tables et calcul des variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-spine",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.124594Z",
     "iopub.status.idle": "2023-03-30T10:06:20.124971Z",
     "shell.execute_reply": "2023-03-30T10:06:20.124799Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Jointure entre les 2 tables\n",
    "join_on = [\"ENTITY\", \"PERIOD_COMP\", \"COMPTE_NUM\", \"RUBRIQUE_N3\"]\n",
    "db_var = (\n",
    "    pd.merge(db_var, db_comp, how=\"left\", on=join_on)\n",
    "    .drop(\"PERIOD_COMP\", axis=1)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# Création colonne Var V\n",
    "db_var[\"VARV\"] = db_var[\"VALUE\"] - db_var[\"VALUE_N-1\"]\n",
    "\n",
    "# Création colonne Var P (%)\n",
    "db_var[\"VARP\"] = db_var[\"VARV\"] / db_var[\"VALUE_N-1\"]\n",
    "\n",
    "db_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-estonia",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.126281Z",
     "iopub.status.idle": "2023-03-30T10:06:20.126614Z",
     "shell.execute_reply": "2023-03-30T10:06:20.126454Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_cat = db_var.copy()\n",
    "\n",
    "# Calcul des rubriques niveau 2\n",
    "def rubrique_N2(row):\n",
    "    numero_compte = str(row[\"COMPTE_NUM\"])\n",
    "    value = float(row[\"VALUE\"])\n",
    "\n",
    "    # BILAN SIMPLIFIE type IFRS NIV2\n",
    "\n",
    "    to_check = [\"^10\", \"^11\", \"^12\", \"^13\", \"^14\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"CAPITAUX_PROPRES\"\n",
    "\n",
    "    to_check = [\"^15\", \"^16\", \"^17\", \"^18\", \"^19\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"DETTES_FINANCIERES\"\n",
    "\n",
    "    to_check = [\"^20\", \"^21\", \"^22\", \"^23\", \"^25\", \"^26\", \"^27\", \"^28\", \"^29\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"IMMOBILISATIONS\"\n",
    "\n",
    "    to_check = [\"^31\", \"^32\", \"^33\", \"^34\", \"^35\", \"^36\", \"^37\", \"^38\", \"^39\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"STOCKS\"\n",
    "\n",
    "    to_check = [\"^40\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"DETTES_FOURNISSEURS\"\n",
    "\n",
    "    to_check = [\"^41\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"CREANCES_CLIENTS\"\n",
    "\n",
    "    to_check = [\"^42\", \"^43\", \"^44\", \"^45\", \"^46\", \"^47\", \"^48\", \"^49\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        if value > 0:\n",
    "            return \"AUTRES_CREANCES\"\n",
    "        else:\n",
    "            return \"AUTRES_DETTES\"\n",
    "\n",
    "    to_check = [\"^50\", \"^51\", \"^52\", \"^53\", \"^54\", \"^58\", \"^59\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"DISPONIBILITES\"\n",
    "\n",
    "    # COMPTE DE RESULTAT DETAILLE NIV2\n",
    "\n",
    "    to_check = [\"^60\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"ACHATS\"\n",
    "\n",
    "    to_check = [\"^61\", \"^62\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"SERVICES_EXTERIEURS\"\n",
    "\n",
    "    to_check = [\"^63\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"TAXES\"\n",
    "\n",
    "    to_check = [\"^64\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"CHARGES_PERSONNEL\"\n",
    "\n",
    "    to_check = [\"^65\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"AUTRES_CHARGES\"\n",
    "\n",
    "    to_check = [\"^66\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"CHARGES_FINANCIERES\"\n",
    "\n",
    "    to_check = [\"^67\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"CHARGES_EXCEPTIONNELLES\"\n",
    "\n",
    "    to_check = [\"^68\", \"^78\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"AMORTISSEMENTS\"\n",
    "\n",
    "    to_check = [\"^69\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"IMPOT\"\n",
    "\n",
    "    to_check = [\"^70\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"VENTES\"\n",
    "\n",
    "    to_check = [\"^71\", \"^72\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"PRODUCTION_STOCKEE_IMMOBILISEE\"\n",
    "\n",
    "    to_check = [\"^74\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"SUBVENTIONS_D'EXPL.\"\n",
    "\n",
    "    to_check = [\"^75\", \"^791\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"AUTRES_PRODUITS_GESTION_COURANTE\"\n",
    "\n",
    "    to_check = [\"^76\", \"^796\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"PRODUITS_FINANCIERS\"\n",
    "\n",
    "    to_check = [\"^77\", \"^797\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"PRODUITS_EXCEPTIONNELS\"\n",
    "\n",
    "    to_check = [\"^78\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"REPRISES_AMORT._DEP.\"\n",
    "\n",
    "    to_check = [\"^8\"]\n",
    "    if any(re.search(x, numero_compte) for x in to_check):\n",
    "        return \"COMPTES_SPECIAUX\"\n",
    "\n",
    "\n",
    "# Calcul des rubriques niveau 1\n",
    "def rubrique_N1(row):\n",
    "    categorisation = row.RUBRIQUE_N2\n",
    "\n",
    "    # BILAN SIMPLIFIE type IFRS N1\n",
    "\n",
    "    to_check = [\"CAPITAUX_PROPRES\", \"DETTES_FINANCIERES\"]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"PASSIF_NON_COURANT\"\n",
    "\n",
    "    to_check = [\"IMMOBILISATIONS\"]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"ACTIF_NON_COURANT\"\n",
    "\n",
    "    to_check = [\"STOCKS\", \"CREANCES_CLIENTS\", \"AUTRES_CREANCES\"]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"ACTIF_COURANT\"\n",
    "\n",
    "    to_check = [\"DETTES_FOURNISSEURS\", \"AUTRES_DETTES\"]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"PASSIF_COURANT\"\n",
    "\n",
    "    to_check = [\"DISPONIBILITES\"]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"DISPONIBILITES\"\n",
    "\n",
    "    # COMPTE DE RESULTAT SIMPLIFIE N1\n",
    "\n",
    "    to_check = [\"ACHATS\"]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"COUTS_DIRECTS\"\n",
    "\n",
    "    to_check = [\n",
    "        \"SERVICES_EXTERIEURS\",\n",
    "        \"TAXES\",\n",
    "        \"CHARGES_PERSONNEL\",\n",
    "        \"AUTRES_CHARGES\",\n",
    "        \"AMORTISSEMENTS\",\n",
    "    ]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"CHARGES_EXPLOITATION\"\n",
    "\n",
    "    to_check = [\"CHARGES_FINANCIERES\"]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"CHARGES_FINANCIERES\"\n",
    "\n",
    "    to_check = [\"CHARGES_EXCEPTIONNELLES\", \"IMPOT\"]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"CHARGES_EXCEPTIONNELLES\"\n",
    "\n",
    "    to_check = [\"VENTES\", \"PRODUCTION_STOCKEE_IMMOBILISEE\"]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"CHIFFRE_D'AFFAIRES\"\n",
    "\n",
    "    to_check = [\n",
    "        \"SUBVENTIONS_D'EXPL.\",\n",
    "        \"AUTRES_PRODUITS_GESTION_COURANTE\",\n",
    "        \"REPRISES_AMORT._DEP.\",\n",
    "    ]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"PRODUITS_EXPLOITATION\"\n",
    "\n",
    "    to_check = [\"PRODUITS_FINANCIERS\"]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"PRODUITS_FINANCIERS\"\n",
    "\n",
    "    to_check = [\"PRODUITS_EXCEPTIONNELS\"]\n",
    "    if any(re.search(x, categorisation) for x in to_check):\n",
    "        return \"PRODUITS_EXCEPTIONNELS\"\n",
    "\n",
    "\n",
    "# Calcul des rubriques niveau 0\n",
    "def rubrique_N0(row):\n",
    "    masse = row.RUBRIQUE_N1\n",
    "\n",
    "    to_check = [\"ACTIF_NON_COURANT\", \"ACTIF_COURANT\", \"DISPONIBILITES\"]\n",
    "    if any(re.search(x, masse) for x in to_check):\n",
    "        return \"ACTIF\"\n",
    "\n",
    "    to_check = [\"PASSIF_NON_COURANT\", \"PASSIF_COURANT\"]\n",
    "    if any(re.search(x, masse) for x in to_check):\n",
    "        return \"PASSIF\"\n",
    "\n",
    "    to_check = [\n",
    "        \"COUTS_DIRECTS\",\n",
    "        \"CHARGES_EXPLOITATION\",\n",
    "        \"CHARGES_FINANCIERES\",\n",
    "        \"CHARGES_EXCEPTIONNELLES\",\n",
    "    ]\n",
    "    if any(re.search(x, masse) for x in to_check):\n",
    "        return \"CHARGES\"\n",
    "\n",
    "    to_check = [\n",
    "        \"CHIFFRE_D'AFFAIRES\",\n",
    "        \"PRODUITS_EXPLOITATION\",\n",
    "        \"PRODUITS_FINANCIERS\",\n",
    "        \"PRODUITS_EXCEPTIONNELS\",\n",
    "    ]\n",
    "    if any(re.search(x, masse) for x in to_check):\n",
    "        return \"PRODUITS\"\n",
    "\n",
    "\n",
    "# Mapping des rubriques\n",
    "db_cat[\"RUBRIQUE_N2\"] = db_cat.apply(lambda row: rubrique_N2(row), axis=1)\n",
    "db_cat[\"RUBRIQUE_N1\"] = db_cat.apply(lambda row: rubrique_N1(row), axis=1)\n",
    "db_cat[\"RUBRIQUE_N0\"] = db_cat.apply(lambda row: rubrique_N0(row), axis=1)\n",
    "\n",
    "\n",
    "# Reorganisation colonne\n",
    "to_select = [\n",
    "    \"ENTITY\",\n",
    "    \"PERIOD\",\n",
    "    \"COMPTE_NUM\",\n",
    "    \"RUBRIQUE_N0\",\n",
    "    \"RUBRIQUE_N1\",\n",
    "    \"RUBRIQUE_N2\",\n",
    "    \"RUBRIQUE_N3\",\n",
    "    \"VALUE\",\n",
    "    \"VALUE_N-1\",\n",
    "    \"VARV\",\n",
    "    \"VARP\",\n",
    "]\n",
    "db_cat = db_cat[to_select]\n",
    "\n",
    "db_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-superintendent",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Modèles de données des graphiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-prophet",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### REF_ENTITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-toronto",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.127585Z",
     "iopub.status.idle": "2023-03-30T10:06:20.127921Z",
     "shell.execute_reply": "2023-03-30T10:06:20.127759Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation du dataset ref_entite\n",
    "dataset_entite = db_cat.copy()\n",
    "\n",
    "# Regrouper par entite\n",
    "to_group = [\"ENTITY\"]\n",
    "to_agg = {\"ENTITY\": \"max\"}\n",
    "dataset_entite = dataset_entite.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Affichage du modèle de donnée\n",
    "dataset_entite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-gates",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### REF_SCENARIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-housing",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.128812Z",
     "iopub.status.idle": "2023-03-30T10:06:20.129207Z",
     "shell.execute_reply": "2023-03-30T10:06:20.129017Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation du dataset ref_scenario\n",
    "dataset_scenario = db_cat.copy()\n",
    "\n",
    "# Regrouper par entite\n",
    "to_group = [\"PERIOD\"]\n",
    "to_agg = {\"PERIOD\": \"max\"}\n",
    "dataset_scenario = dataset_scenario.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Affichage du modèle de donnée\n",
    "dataset_scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-palestine",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### KPIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-buddy",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.130141Z",
     "iopub.status.idle": "2023-03-30T10:06:20.130516Z",
     "shell.execute_reply": "2023-03-30T10:06:20.130348Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation du dataset KPIS (CA, MARGE, EBE, BFR, CC, DF)\n",
    "dataset_kpis = db_cat.copy()\n",
    "\n",
    "# KPIs CA\n",
    "dataset_kpis_ca = dataset_kpis[dataset_kpis.RUBRIQUE_N1.isin([\"CHIFFRE_D'AFFAIRES\"])]\n",
    "\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N1\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_kpis_ca = dataset_kpis_ca.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Passage value postif\n",
    "dataset_kpis_ca[\"VALUE\"] = dataset_kpis_ca[\"VALUE\"] * -1\n",
    "\n",
    "\n",
    "# COUTS_DIRECTS\n",
    "dataset_kpis_ha = dataset_kpis[dataset_kpis.RUBRIQUE_N1.isin([\"COUTS_DIRECTS\"])]\n",
    "\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N1\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_kpis_ha = dataset_kpis_ha.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Passage value négatif\n",
    "dataset_kpis_ha[\"VALUE\"] = dataset_kpis_ha[\"VALUE\"] * -1\n",
    "\n",
    "\n",
    "# KPIs MARGE BRUTE (CA - COUTS DIRECTS)\n",
    "dataset_kpis_mb = dataset_kpis_ca.copy()\n",
    "dataset_kpis_mb = pd.concat([dataset_kpis_mb, dataset_kpis_ha], axis=0, sort=False)\n",
    "\n",
    "to_group = [\"ENTITY\", \"PERIOD\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "\n",
    "dataset_kpis_mb = dataset_kpis_mb.groupby(to_group, as_index=False).agg(to_agg)\n",
    "dataset_kpis_mb[\"RUBRIQUE_N1\"] = \"MARGE\"\n",
    "dataset_kpis_mb = dataset_kpis_mb[[\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N1\", \"VALUE\"]]\n",
    "\n",
    "\n",
    "# CHARGES EXTERNES\n",
    "dataset_kpis_ce = dataset_kpis[dataset_kpis.RUBRIQUE_N2.isin([\"SERVICES_EXTERIEURS\"])]\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N2\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_kpis_ce = dataset_kpis_ce.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Passage value negatif\n",
    "dataset_kpis_ce[\"VALUE\"] = dataset_kpis_ce[\"VALUE\"] * -1\n",
    "\n",
    "\n",
    "# IMPOTS\n",
    "dataset_kpis_ip = dataset_kpis[dataset_kpis.RUBRIQUE_N2.isin([\"TAXES\"])]\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N2\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_kpis_ip = dataset_kpis_ip.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Passage value negatif\n",
    "dataset_kpis_ip[\"VALUE\"] = dataset_kpis_ip[\"VALUE\"] * -1\n",
    "\n",
    "\n",
    "# CHARGES DE PERSONNEL\n",
    "dataset_kpis_cp = dataset_kpis[dataset_kpis.RUBRIQUE_N2.isin([\"CHARGES_PERSONNEL\"])]\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N2\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_kpis_cp = dataset_kpis_cp.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Passage value negatif\n",
    "dataset_kpis_cp[\"VALUE\"] = dataset_kpis_cp[\"VALUE\"] * -1\n",
    "\n",
    "\n",
    "# AUTRES_CHARGES\n",
    "dataset_kpis_ac = dataset_kpis[dataset_kpis.RUBRIQUE_N2.isin([\"AUTRES_CHARGES\"])]\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N2\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_kpis_ac = dataset_kpis_ac.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Passage value negatif\n",
    "dataset_kpis_ac[\"VALUE\"] = dataset_kpis_ac[\"VALUE\"] * -1\n",
    "\n",
    "\n",
    "# SUBVENTIONS D'EXPLOITATION\n",
    "dataset_kpis_ac = dataset_kpis[dataset_kpis.RUBRIQUE_N2.isin([\"SUBVENTIONS_D'EXPL.\"])]\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N2\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_kpis_ac = dataset_kpis_ac.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "\n",
    "# KPIs EBE = MARGE - CHARGES EXTERNES - TAXES - CHARGES PERSONNEL - AUTRES CHARGES + SUBVENTION D'EXPLOITATION\n",
    "dataset_kpis_ebe = dataset_kpis_mb.copy()\n",
    "dataset_kpis_ebe = pd.concat(\n",
    "    [\n",
    "        dataset_kpis_ebe,\n",
    "        dataset_kpis_ce,\n",
    "        dataset_kpis_ip,\n",
    "        dataset_kpis_cp,\n",
    "        dataset_kpis_ac,\n",
    "    ],\n",
    "    axis=0,\n",
    "    sort=False,\n",
    ")\n",
    "\n",
    "to_group = [\"ENTITY\", \"PERIOD\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "\n",
    "dataset_kpis_ebe = dataset_kpis_ebe.groupby(to_group, as_index=False).agg(to_agg)\n",
    "dataset_kpis_ebe[\"RUBRIQUE_N1\"] = \"EBE\"\n",
    "dataset_kpis_ebe = dataset_kpis_ebe[[\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N1\", \"VALUE\"]]\n",
    "\n",
    "\n",
    "# KPIs CREANCES CLIENTS\n",
    "dataset_kpis_cc = dataset_kpis[dataset_kpis.RUBRIQUE_N2.isin([\"CREANCES_CLIENTS\"])]\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N2\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_kpis_cc = dataset_kpis_cc.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Renommage colonne\n",
    "to_rename = {\"RUBRIQUE_N2\": \"RUBRIQUE_N1\"}\n",
    "dataset_kpis_cc = dataset_kpis_cc.rename(columns=to_rename)\n",
    "\n",
    "\n",
    "# KPIs STOCKS\n",
    "dataset_kpis_st = dataset_kpis[dataset_kpis.RUBRIQUE_N2.isin([\"STOCKS\"])]\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N2\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_kpis_st = dataset_kpis_st.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Renommage colonne\n",
    "to_rename = {\"RUBRIQUE_N2\": \"RUBRIQUE_N1\"}\n",
    "dataset_kpis_st = dataset_kpis_st.rename(columns=to_rename)\n",
    "\n",
    "\n",
    "# KPIs DETTES FOURNISSEURS\n",
    "dataset_kpis_df = dataset_kpis[dataset_kpis.RUBRIQUE_N2.isin([\"DETTES_FOURNISSEURS\"])]\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N2\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_kpis_df = dataset_kpis_df.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Renommage colonne\n",
    "to_rename = {\"RUBRIQUE_N2\": \"RUBRIQUE_N1\"}\n",
    "dataset_kpis_df = dataset_kpis_df.rename(columns=to_rename)\n",
    "\n",
    "# Passage value positif\n",
    "dataset_kpis_df[\"VALUE\"] = dataset_kpis_df[\"VALUE\"].abs()\n",
    "\n",
    "\n",
    "# KPIs BFR = CREANCES + STOCKS - DETTES FOURNISSEURS\n",
    "dataset_kpis_bfr_df = dataset_kpis_df.copy()\n",
    "\n",
    "# Passage dette fournisseur value négatif\n",
    "dataset_kpis_bfr_df[\"VALUE\"] = dataset_kpis_bfr_df[\"VALUE\"] * -1\n",
    "\n",
    "dataset_kpis_bfr_df = pd.concat(\n",
    "    [dataset_kpis_cc, dataset_kpis_st, dataset_kpis_bfr_df], axis=0, sort=False\n",
    ")\n",
    "\n",
    "to_group = [\"ENTITY\", \"PERIOD\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_kpis_bfr_df = dataset_kpis_bfr_df.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "# Creation colonne Rubrique_N1 = BFR\n",
    "dataset_kpis_bfr_df[\"RUBRIQUE_N1\"] = \"BFR\"\n",
    "\n",
    "# Reorganisation colonne\n",
    "dataset_kpis_bfr_df = dataset_kpis_bfr_df[[\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N1\", \"VALUE\"]]\n",
    "\n",
    "\n",
    "# Creation du dataset final\n",
    "dataset_kpis_final = pd.concat(\n",
    "    [\n",
    "        dataset_kpis_ca,\n",
    "        dataset_kpis_mb,\n",
    "        dataset_kpis_ebe,\n",
    "        dataset_kpis_cc,\n",
    "        dataset_kpis_st,\n",
    "        dataset_kpis_df,\n",
    "        dataset_kpis_bfr_df,\n",
    "    ],\n",
    "    axis=0,\n",
    "    sort=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Creation colonne COMP\n",
    "dataset_kpis_final[\"PERIOD_COMP\"] = (\n",
    "    dataset_kpis_final[\"PERIOD\"].str[:4].astype(int) - 1\n",
    ").astype(str) + dataset_kpis_final[\"PERIOD\"].str[-3:]\n",
    "dataset_kpis_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-grammar",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.131255Z",
     "iopub.status.idle": "2023-03-30T10:06:20.131582Z",
     "shell.execute_reply": "2023-03-30T10:06:20.131421Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creation base comparable pour dataset_kpis\n",
    "dataset_kpis_final_comp = dataset_kpis_final.copy()\n",
    "\n",
    "# Suppression de la colonne période\n",
    "dataset_kpis_final_comp = dataset_kpis_final_comp.drop(\"PERIOD_COMP\", axis=1)\n",
    "\n",
    "# Renommage des colonnes\n",
    "to_rename = {\"VALUE\": \"VALUE_N-1\", \"PERIOD\": \"PERIOD_COMP\"}\n",
    "dataset_kpis_final_comp = dataset_kpis_final_comp.rename(columns=to_rename)\n",
    "dataset_kpis_final_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-consultation",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.132492Z",
     "iopub.status.idle": "2023-03-30T10:06:20.132821Z",
     "shell.execute_reply": "2023-03-30T10:06:20.132659Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Jointure entre les 2 tables dataset_kpis_final et dataset_kpis_vf\n",
    "join_on = [\"ENTITY\", \"PERIOD_COMP\", \"RUBRIQUE_N1\"]\n",
    "dataset_kpis_final = (\n",
    "    pd.merge(dataset_kpis_final, dataset_kpis_final_comp, how=\"left\", on=join_on)\n",
    "    .drop(\"PERIOD_COMP\", axis=1)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# Création colonne Var V\n",
    "dataset_kpis_final[\"VARV\"] = (\n",
    "    dataset_kpis_final[\"VALUE\"] - dataset_kpis_final[\"VALUE_N-1\"]\n",
    ")\n",
    "\n",
    "# Création colonne Var P (%)\n",
    "dataset_kpis_final[\"VARP\"] = (\n",
    "    dataset_kpis_final[\"VARV\"] / dataset_kpis_final[\"VALUE_N-1\"]\n",
    ")\n",
    "\n",
    "dataset_kpis_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-child",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### EVOLUTION CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-azerbaijan",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.133667Z",
     "iopub.status.idle": "2023-03-30T10:06:20.133993Z",
     "shell.execute_reply": "2023-03-30T10:06:20.133832Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation du dataset evol_ca\n",
    "dataset_evol_ca = db_enr.copy()\n",
    "\n",
    "# Filtre COMPTE_NUM = Chiffre d'Affaire (RUBRIQUE N1)\n",
    "dataset_evol_ca = dataset_evol_ca[\n",
    "    dataset_evol_ca[\"COMPTE_NUM\"].str.contains(r\"^70|^71|^72\")\n",
    "]\n",
    "\n",
    "# Regroupement\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"MONTH\", \"MONTH_INDEX\", \"RUBRIQUE_N3\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_evol_ca = dataset_evol_ca.groupby(to_group, as_index=False).agg(to_agg)\n",
    "\n",
    "dataset_evol_ca[\"VALUE\"] = dataset_evol_ca[\"VALUE\"].abs()\n",
    "\n",
    "\n",
    "# Calcul de la somme cumulée\n",
    "dataset_evol_ca = dataset_evol_ca.sort_values(\n",
    "    by=[\"ENTITY\", \"PERIOD\", \"MONTH_INDEX\"]\n",
    ").reset_index(drop=True)\n",
    "dataset_evol_ca[\"MONTH_INDEX\"] = pd.to_datetime(\n",
    "    dataset_evol_ca[\"MONTH_INDEX\"], format=\"%m\"\n",
    ").dt.strftime(\"%m\")\n",
    "dataset_evol_ca[\"VALUE_CUM\"] = dataset_evol_ca.groupby(\n",
    "    [\"ENTITY\", \"PERIOD\"], as_index=True\n",
    ").agg({\"VALUE\": \"cumsum\"})\n",
    "\n",
    "# Affichage du modèle de donnée\n",
    "dataset_evol_ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-harvard",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### CHARGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-equilibrium",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.134877Z",
     "iopub.status.idle": "2023-03-30T10:06:20.135272Z",
     "shell.execute_reply": "2023-03-30T10:06:20.135089Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation du dataset charges\n",
    "dataset_charges = db_cat.copy()\n",
    "\n",
    "# Filtre RUBRIQUE_N0 = CHARGES\n",
    "dataset_charges = dataset_charges[dataset_charges[\"RUBRIQUE_N0\"] == \"CHARGES\"]\n",
    "\n",
    "# Mettre en valeur positive VALUE\n",
    "dataset_charges[\"VALUE\"] = dataset_charges[\"VALUE\"].abs()\n",
    "\n",
    "# Affichage du modèle de donnée\n",
    "dataset_charges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-generator",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "#### POSITIONS TRESORERIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-difficulty",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.136116Z",
     "iopub.status.idle": "2023-03-30T10:06:20.136577Z",
     "shell.execute_reply": "2023-03-30T10:06:20.136365Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation du dataset trésorerie\n",
    "dataset_treso = db_enr.copy()\n",
    "\n",
    "# Filtre RUBRIQUE_N1 = TRESORERIE\n",
    "dataset_treso = dataset_treso[\n",
    "    dataset_treso[\"COMPTE_NUM\"].str.contains(r\"^5\")\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Cash in / Cash out ?\n",
    "dataset_treso.loc[dataset_treso.VALUE > 0, \"CASH_IN\"] = dataset_treso.VALUE\n",
    "dataset_treso.loc[dataset_treso.VALUE < 0, \"CASH_OUT\"] = dataset_treso.VALUE\n",
    "\n",
    "# Regroupement\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"MONTH\", \"MONTH_INDEX\"]\n",
    "to_agg = {\"VALUE\": \"sum\", \"CASH_IN\": \"sum\", \"CASH_OUT\": \"sum\"}\n",
    "dataset_treso = dataset_treso.groupby(to_group, as_index=False).agg(to_agg).fillna(0)\n",
    "\n",
    "# Cumul par période\n",
    "dataset_treso = dataset_treso.sort_values([\"ENTITY\", \"PERIOD\", \"MONTH_INDEX\"])\n",
    "dataset_treso[\"MONTH_INDEX\"] = pd.to_datetime(\n",
    "    dataset_treso[\"MONTH_INDEX\"], format=\"%m\"\n",
    ").dt.strftime(\"%m\")\n",
    "dataset_treso[\"VALUE_LINE\"] = dataset_treso.groupby(\n",
    "    [\"ENTITY\", \"PERIOD\"], as_index=True\n",
    ").agg({\"VALUE\": \"cumsum\"})\n",
    "\n",
    "# Mettre en valeur positive CASH_OUT\n",
    "dataset_treso[\"CASH_OUT\"] = dataset_treso[\"CASH_OUT\"].abs()\n",
    "\n",
    "# Affichage du modèle de donnée\n",
    "dataset_treso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-california",
   "metadata": {
    "papermill": {},
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### BILAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-secret",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.137373Z",
     "iopub.status.idle": "2023-03-30T10:06:20.137853Z",
     "shell.execute_reply": "2023-03-30T10:06:20.137677Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation du dataset Bilan\n",
    "dataset_bilan = db_cat.copy()\n",
    "\n",
    "# Filtre RUBRIQUE_N0 = ACTIF & PASSIF\n",
    "dataset_bilan = dataset_bilan[(dataset_bilan[\"RUBRIQUE_N0\"].isin([\"ACTIF\", \"PASSIF\"]))]\n",
    "\n",
    "# Regroupement R0/R1/R2\n",
    "to_group = [\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N0\", \"RUBRIQUE_N1\", \"RUBRIQUE_N2\"]\n",
    "to_agg = {\"VALUE\": \"sum\"}\n",
    "dataset_bilan = dataset_bilan.groupby(to_group, as_index=False).agg(to_agg).fillna(0)\n",
    "\n",
    "\n",
    "# Mettre en valeur positive VALUE\n",
    "dataset_bilan[\"VALUE\"] = dataset_bilan[\"VALUE\"].abs()\n",
    "\n",
    "# Selectionner les colonnes\n",
    "to_select = [\"ENTITY\", \"PERIOD\", \"RUBRIQUE_N0\", \"RUBRIQUE_N1\", \"RUBRIQUE_N2\", \"VALUE\"]\n",
    "dataset_bilan = dataset_bilan[to_select]\n",
    "\n",
    "# Affichage du modèle de donnée\n",
    "dataset_bilan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-birthday",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-clone",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Sauvegarde des fichiers en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-story",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.138708Z",
     "iopub.status.idle": "2023-03-30T10:06:20.139080Z",
     "shell.execute_reply": "2023-03-30T10:06:20.138912Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_to_csv(df, filename, output_folder=OUTPUT_FOLDER):\n",
    "    # Init\n",
    "    file_path = f'{output_folder}{filename}'\n",
    "    \n",
    "    # Sauvegarde en csv\n",
    "    df.to_csv(file_path, sep=\";\", decimal=\",\", index=False)\n",
    "\n",
    "    # Création du lien url\n",
    "    naas_link = naas.asset.add(file_path)\n",
    "\n",
    "    # Création de la ligne\n",
    "    data = {\n",
    "        \"OBJET\": filename,\n",
    "        \"URL\": naas_link,\n",
    "        \"DATE_EXTRACT\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    }\n",
    "    return pd.DataFrame([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-tract",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.139869Z",
     "iopub.status.idle": "2023-03-30T10:06:20.140183Z",
     "shell.execute_reply": "2023-03-30T10:06:20.140023Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_logo = {\n",
    "    \"OBJET\": \"Logo\",\n",
    "    \"URL\": LOGO,\n",
    "    \"DATE_EXTRACT\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "}\n",
    "logo = pd.DataFrame([dataset_logo])\n",
    "logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-evolution",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.141134Z",
     "iopub.status.idle": "2023-03-30T10:06:20.141458Z",
     "shell.execute_reply": "2023-03-30T10:06:20.141299Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "color = {\"name\": \"Color\", \"dataColors\": [COLOR_1, COLOR_2]}\n",
    "\n",
    "color_json_path = f'{OUTPUT_FOLDER}color.json'\n",
    "\n",
    "with open(color_json_path, \"w\") as write_file:\n",
    "    json.dump(color, write_file)\n",
    "\n",
    "dataset_color = {\n",
    "    \"OBJET\": \"Color\",\n",
    "    \"URL\": naas.asset.add(color_json_path),\n",
    "    \"DATE_EXTRACT\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "}\n",
    "pbi_color = pd.DataFrame([dataset_color])\n",
    "pbi_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-relative",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.142319Z",
     "iopub.status.idle": "2023-03-30T10:06:20.142648Z",
     "shell.execute_reply": "2023-03-30T10:06:20.142486Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "entite = df_to_csv(dataset_entite, \"dataset_entite.csv\")\n",
    "entite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-postage",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.144259Z",
     "iopub.status.idle": "2023-03-30T10:06:20.144762Z",
     "shell.execute_reply": "2023-03-30T10:06:20.144585Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "scenario = df_to_csv(dataset_scenario, \"dataset_scenario.csv\")\n",
    "scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-editing",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.145555Z",
     "iopub.status.idle": "2023-03-30T10:06:20.146013Z",
     "shell.execute_reply": "2023-03-30T10:06:20.145838Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "kpis = df_to_csv(dataset_kpis_final, \"dataset_kpis_final.csv\")\n",
    "kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-rates",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.146787Z",
     "iopub.status.idle": "2023-03-30T10:06:20.147263Z",
     "shell.execute_reply": "2023-03-30T10:06:20.147071Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "evol_ca = df_to_csv(dataset_evol_ca, \"dataset_evol_ca.csv\")\n",
    "evol_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-sequence",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.148112Z",
     "iopub.status.idle": "2023-03-30T10:06:20.148589Z",
     "shell.execute_reply": "2023-03-30T10:06:20.148400Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "charges = df_to_csv(dataset_charges, \"dataset_charges.csv\")\n",
    "charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-tampa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.149364Z",
     "iopub.status.idle": "2023-03-30T10:06:20.149830Z",
     "shell.execute_reply": "2023-03-30T10:06:20.149655Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "treso = df_to_csv(dataset_treso, \"dataset_treso.csv\")\n",
    "treso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-textbook",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.150602Z",
     "iopub.status.idle": "2023-03-30T10:06:20.151061Z",
     "shell.execute_reply": "2023-03-30T10:06:20.150888Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "bilan = df_to_csv(dataset_bilan, \"dataset_bilan.csv\")\n",
    "bilan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-hypothesis",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Création du fichier à intégrer dans PowerBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-species",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.151844Z",
     "iopub.status.idle": "2023-03-30T10:06:20.152302Z",
     "shell.execute_reply": "2023-03-30T10:06:20.152127Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_powerbi = pd.concat(\n",
    "    [logo, pbi_color, entite, scenario, kpis, evol_ca, charges, treso, bilan], axis=0\n",
    ")\n",
    "db_powerbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-aberdeen",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-30T10:06:20.153142Z",
     "iopub.status.idle": "2023-03-30T10:06:20.153605Z",
     "shell.execute_reply": "2023-03-30T10:06:20.153429Z"
    },
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_to_csv(db_powerbi, \"powerbi.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "488da1e7-5583-478f-b198-277886651611",
   "notebook_path": "FEC/FEC_Creer_un_dashboard_PowerBI.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
